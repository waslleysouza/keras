{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[20], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = to_categorical(train_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.1794 - acc: 0.9445 - val_loss: 0.0452 - val_acc: 0.9854\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 38s 626us/step - loss: 0.0492 - acc: 0.9848 - val_loss: 0.0369 - val_acc: 0.9881\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 37s 609us/step - loss: 0.0370 - acc: 0.9884 - val_loss: 0.0306 - val_acc: 0.9897\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.0267 - acc: 0.9914 - val_loss: 0.0315 - val_acc: 0.9888\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 37s 614us/step - loss: 0.0220 - acc: 0.9934 - val_loss: 0.0331 - val_acc: 0.9893\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 37s 618us/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0313 - val_acc: 0.9914\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 38s 626us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 0.0323 - val_acc: 0.9895\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 37s 625us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 37s 623us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0274 - val_acc: 0.9920\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 37s 624us/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0229 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, \n",
    "                    batch_size=64, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36tf]",
   "language": "python",
   "name": "conda-env-py36tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
